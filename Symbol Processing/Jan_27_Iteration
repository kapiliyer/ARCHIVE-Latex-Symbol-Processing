{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Jan_27_Iteration","provenance":[{"file_id":"1sxNIjtTqQQKZZJms43DUHht4DQLue8UL","timestamp":1643158686027}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"_B2KowBG8Zx_","executionInfo":{"status":"ok","timestamp":1643348107442,"user_tz":480,"elapsed":2613,"user":{"displayName":"Michael Robert Doboli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13681449374036728389"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"79007a5d-ad97-4dd9-c721-3a9be3da0b04"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/.shortcut-targets-by-id/1Ip0tGIOuwJNvhITLBA4pbOcMNg9Lv-mq/primary_description\n"]}],"source":["# this mounts your Google Drive to the Colab VM.\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# enter the foldername in your Drive where you have saved the unzipped\n","# workshop folder, e.g. 'acmlab/workshops/project'\n","FOLDERNAME = 'primary_description'\n","assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","\n","# now that we've mounted your Drive, this ensures that\n","# the Python interpreter of the Colab VM can load\n","# python files from within it.\n","import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n","\n","%cd /content/drive/My\\ Drive/$FOLDERNAME/"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"l4pMi_3HCdxb","executionInfo":{"status":"ok","timestamp":1643348109224,"user_tz":480,"elapsed":1787,"user":{"displayName":"Michael Robert Doboli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13681449374036728389"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7749d6ee-40ad-4ace-f40f-f2ecf11471c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}],"source":["import numpy as np\n","import os\n","from sklearn.metrics import f1_score\n","import pandas as pd\n","from textblob import TextBlob\n","import nltk\n","import re\n","import difflib\n","\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('wordnet')\n","\n","from nltk import word_tokenize, pos_tag\n","from nltk.corpus import wordnet\n","\n","from IPython.display import display\n","\n","# import stanza\n","# stanza.install_corenlp()\n","# import spacy\n","# nltk.download('brown')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"VVkvU5UR6h6N","executionInfo":{"status":"ok","timestamp":1643348109424,"user_tz":480,"elapsed":204,"user":{"displayName":"Michael Robert Doboli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13681449374036728389"}}},"outputs":[],"source":["data = pd.read_json(\"Practice/cs.ai-ann0.json\")\n","# text_data.to_dict()"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"fcac7jyqAIe3","executionInfo":{"status":"ok","timestamp":1643348109615,"user_tz":480,"elapsed":193,"user":{"displayName":"Michael Robert Doboli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13681449374036728389"}}},"outputs":[],"source":["def extract_primary_description(entity): #Entity is a dicitionary.\n","  output = {}\n","  for key in entity.keys():\n","    if entity[key]['label'] == \"PRIMARY\":\n","      output[key] = entity[key]\n","  return output\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"od1I_w4VNa0q","executionInfo":{"status":"ok","timestamp":1643348109754,"user_tz":480,"elapsed":142,"user":{"displayName":"Michael Robert Doboli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13681449374036728389"}}},"outputs":[],"source":["lemmatizer = nltk.WordNetLemmatizer()\n","def setup(text):\n","\n","  #word tokenizeing and part-of-speech tagger\n","  document = text\n","  tokens = [nltk.word_tokenize(sent) for sent in [document]]\n","  postag = [nltk.pos_tag(sent) for sent in tokens][0]\n","\n","  # Rule for NP chunk and VB Chunk\n","  grammar = r\"\"\"\n","      NBAR:\n","          {<NN.*|JJ>*<NN.*>}  # Nouns and Adjectives, terminated with Nouns\n","          {<RB.?>*<VB.?>*<JJ>*<VB.?>+<VB>?} # Verbs and Verb Phrases\n","          \n","      NP:\n","          {<NBAR>}\n","          {<NBAR><IN><NBAR>}  # Above, connected with in/of/etc...\n","          \n","  \"\"\"\n","  #Chunking\n","  cp = nltk.RegexpParser(grammar)\n","\n","  # the result is a tree\n","  tree = cp.parse(postag)\n","  return tree\n","\n","def leaves(tree):\n","    \"\"\"Finds NP (nounphrase) leaf nodes of a chunk tree.\"\"\"\n","    for subtree in tree.subtrees(filter = lambda t: t.label() =='NP'):\n","        yield subtree.leaves()\n","        \n","def get_word_postag(word):\n","    if pos_tag([word])[0][1].startswith('J'):\n","        return wordnet.ADJ\n","    if pos_tag([word])[0][1].startswith('V'):\n","        return wordnet.VERB\n","    if pos_tag([word])[0][1].startswith('N'):\n","        return wordnet.NOUN\n","    else:\n","        return wordnet.NOUN\n","    \n","def normalise(word):\n","    \"\"\"Normalises words to lowercase and stems and lemmatizes it.\"\"\"\n","    # word = word.lower()\n","    # postag = get_word_postag(word)\n","    # word = lemmatizer.lemmatize(word, postag)\n","    return word\n","\n","def get_terms(tree):    \n","    for leaf in leaves(tree):\n","        terms = [normalise(w) for w,t in leaf]\n","        yield terms\n","\n","def getNounPhrases(text): ##Text is a sentence##\n","  answer = {}\n","  wordsToRemove = ['be', 'is', 'are', 'was', 'were', 'been', 'being']\n","  tree = setup(text)\n","\n","  terms = get_terms(tree)\n","\n","  features = []\n","\n","  for term in terms:\n","      _term = ''\n","      for word in term:\n","        _term += ' ' + word\n","\n","      if not any(x in _term.split() for x in wordsToRemove) and '\\\\' not in _term:\n","        features.append(_term.strip())\n","\n","  res = []\n","  res += re.findall(r\"(?<=\\$\\sbe\\s)(.*?)(?=\\.|\\,|\\;|\\:|\\!|\\?|and)\", text)\n","  res += re.findall(r\"(?<=\\$\\srepresent\\s)(.*?)(?=\\.|\\,|\\;|\\:|\\!|\\?|and)\", text)\n","  res += re.findall(r\"(?<=\\$\\srepresents\\s)(.*?)(?=\\.|\\,|\\;|\\:|\\!|\\?|and)\", text)\n","  res += re.findall(r\"(?<=\\$\\sdenote\\s)(.*?)(?=\\.|\\,|\\;|\\:|\\!|\\?|and)\", text)\n","  res += re.findall(r\"(?<=\\$\\sdenotes\\s)(.*?)(?=\\.|\\,|\\;|\\:|\\!|\\?|and)\", text)\n","  res += re.findall(r\"(?<=\\$\\sis\\s)(.*?)(?=\\.|\\,|\\;|\\:|\\!|\\?|\\\\|and)\", text)\n","  res += re.findall(r\"(?<=\\sof\\s)(.*?)(?=\\$|\\.|\\,|\\;|\\:|\\!|\\?|\\\\|and)\", text)\n","  result1 = re.findall(r\"(?<=\\sthe\\s)(.*?)(?=\\$|\\.|\\,|\\;|\\:|\\!|\\?|\\\\|and)\", text)\n","  for i in range(len(result1)):\n","    result1[i] = 'the ' + result1[i]\n","  res += result1\n","\n","  result2 = re.findall(r\"(?<=\\sThe\\s)(.*?)(?=\\$|\\.|\\,|\\;|\\:|\\!|\\?|\\\\)\", text)\n","  for i in range(len(result2)):\n","    result2[i] = 'The ' + result2[i]\n","  res += result2\n","\n","  result3 = re.findall(r\"(?<=\\sa\\s)(.*?)(?=\\$|\\.|\\,|\\;|\\:|\\!|\\?|\\\\)\", text)\n","  for i in range(len(result3)):\n","    result3[i] = 'a ' + result3[i]\n","  res += result3\n","\n","  for phrase in res:\n","    features.append(phrase.strip())\n","\n","  return features"]},{"cell_type":"code","source":["# nounPhrases = {}\n","# text = data.loc[\"text\"][1]\n","# nounPhrases = getNounPhrases(text)\n","# print(nounPhrases)"],"metadata":{"id":"qdcnk6r0_61W","executionInfo":{"status":"ok","timestamp":1643348109754,"user_tz":480,"elapsed":3,"user":{"displayName":"Michael Robert Doboli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13681449374036728389"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["\n","# substrings surrounded by delimiter pairs are math text\n","delimiters = {'\\\\(': '\\\\)', '$': '$', '$$': '$$', '\\\\begin{math}': '\\\\end{math}', '\\\\[': '\\\\]', '\\\\begin{displaymath}': '\\\\end{displaymath}', '\\\\begin{equation}': '\\\\end{equation}', '\\\\begin{align}': '\\\\end{align}', '\\\\begin{eqnarray}': '\\\\end{eqnarray}', '\\\\begin{array}': '\\\\end{array}', '(': ')'}\n","# substrings to the left and right of a splitter are considered separate symbols\n","splitters = ['=', '<', '>', '<=', '=>', '\\\\leq', '\\\\geq', '\\\\leftarrow' '\\\\rightarrow' '\\\\longleftarrow' '\\\\longrightarrow' '\\\\Leftarrow' '\\\\Rightarrow' '\\\\Longleftarrow' '\\\\Longrightarrow' '\\\\leftrightarrow' '\\\\Longleftrightarrow' '\\\\mapsto' '\\\\longmapsto' '\\\\neq', '\\equiv']\n","\n","def getSymbols(string, dictionary): # given a string, returns a dictionary of each symbol, its start index, and its end index\n","  temp = {}\n","\n","  for start, end in dictionary.items(): # grab each pair of delimiters\n","    new = string # scan the complete string for each pair of delimiters\n","    while True:   \n","      a = new.find(start)\n","      a_shift = a + len(start) # first delimiter\n","      b = new.find(end, a_shift) # second delimiter\n","      if a == -1 or b == -1: # if pair of delimiters are not present, go to the next pair of delimiters\n","        break\n","      else: # if pair of delimiters are present, add the symbols and locations to the dict\n","        result = new[a_shift:b]\n","        if (start != '(' or (result.isupper() and len(result.split())) <= 1) and result.strip() != '': # the (parentheses) delimiter pair only surround abbreviations, i.e. single full-caps words\n","          temp[result] = (a_shift, b)\n","        new = new[b + len(end):] # search for the same pair of delimiters located AFTER the pair we have just identified\n","  \n","  symbols = dict(temp) # make two copies -- one to iterate over and one to store the split symbols\n","\n","  for symbol, location in temp.items(): # recognize symbols separately in equalities/inequalities/implications\n","    (start, end) = location\n","    for splitter in splitters:\n","      if splitter in symbol:\n","        split = [sym.strip() for sym in symbol.split(splitter)]\n","        symbols[split[0]] = (start, start + len(split[0]))\n","        symbols[split[-1]] = (end - len(split[1]), end)\n","        try: # delete the unsplit symbol\n","          del symbols[symbol] \n","        except: # sometimes the unsplit symbol will have already been deleted from temp, because it contained more than one splitter\n","          pass \n","\n","  return symbols"],"metadata":{"id":"TXj4LIy84e2b","executionInfo":{"status":"ok","timestamp":1643348109755,"user_tz":480,"elapsed":3,"user":{"displayName":"Michael Robert Doboli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13681449374036728389"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":8,"metadata":{"id":"Z1SxEEev56bu","executionInfo":{"status":"ok","timestamp":1643348109908,"user_tz":480,"elapsed":156,"user":{"displayName":"Michael Robert Doboli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13681449374036728389"}}},"outputs":[],"source":["def calculate_recall(noun_dict, expected):\n","  noun_list = []\n","  for key in noun_dict.keys():\n","      noun_list.append(key)\n","  total = 0\n","  count = 0\n","  primary_descriptor_list = []\n","  for key in expected.keys():\n","    primary_descriptor_list.append(expected[key][\"text\"])\n","  total = len(primary_descriptor_list)  \n","  for descriptor in primary_descriptor_list:\n","    if descriptor in noun_list:  \n","      count += 1\n","      noun_list.remove(descriptor)\n","  return count / total\n","\n","  "]},{"cell_type":"code","execution_count":9,"metadata":{"id":"-iUolarFB9NG","executionInfo":{"status":"ok","timestamp":1643348109908,"user_tz":480,"elapsed":6,"user":{"displayName":"Michael Robert Doboli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13681449374036728389"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2c47acbe-3f50-494b-acba-4365de304054"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'x': (5, 6), '\\x07lpha + \\x08eta': (29, 41)}\n"]}],"source":["text = \"Let $x$ be the number of bins. Let $\\alpha + \\beta$ be the sum of two parameters, which are then used for analysis.\"\n","# text = \"Let $x$ be the number of bins. Let $\\alpha + \\beta$ be the sum of two parameters.\"\n","# res = re.findall(r\"(?<=\\$\\sbe\\s)(.*?)(?=\\.)\", text)\n","# text = \"Let $x$ be the number of bins :\"\n","res = re.findall(r\"(?<=\\$\\sbe\\s)(.*?)(?=\\.|\\,|\\;|\\:|\\!|\\?)\", text)\n","parsed = getSymbols(text, delimiters)\n","print(parsed)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"r7JB_FVNSi4x","executionInfo":{"status":"ok","timestamp":1643348109909,"user_tz":480,"elapsed":7,"user":{"displayName":"Michael Robert Doboli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13681449374036728389"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3f781305-bb1f-4b1c-d85c-60078943534d"},"outputs":[{"output_type":"stream","name":"stdout","text":["['the number of bins']\n"]}],"source":["text = \"Let $x$ represent the number of bins, where $\\alpha + \\beta$ represents the sum of two parameters, which are then used for analysis.\"\n","# text = \"Let $x$ be the number of bins. Let $\\alpha + \\beta$ be the sum of two parameters.\"\n","# res = re.findall(r\"(?<=\\$\\sbe\\s)(.*?)(?=\\.)\", text)\n","# text = \"Let $x$ be the number of bins :\"\n","res = re.findall(r\"(?<=\\$\\srepresent\\s)(.*?)(?=\\.|\\,|\\;|\\:|\\!|\\?)\", text)\n","print(res)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"_5iGVjccQaLk","executionInfo":{"status":"ok","timestamp":1643348109910,"user_tz":480,"elapsed":4,"user":{"displayName":"Michael Robert Doboli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13681449374036728389"}}},"outputs":[],"source":["# print(getNounPhrases(\"Mostly, there just is no default way of determining the paragraph boundary and people tend to work with sentences. Still, the unit of a paragraph might be of a higher value than that of a sentence. Examples might be: coreference resolutions that overlap multiple sentences. Questions that find their answer throughout a whole paragraph. A reader that understands a paragraph better than an isolated sentence. Itâ€™s clear that the signal from a writer is best expressed in a paragraph.\"))"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"bhunPJLjSL0J","executionInfo":{"status":"ok","timestamp":1643348110053,"user_tz":480,"elapsed":147,"user":{"displayName":"Michael Robert Doboli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13681449374036728389"}}},"outputs":[],"source":["# df = data\n","# for column in df:\n","#     wantedOutput = extract_primary_description(df[column][\"entity\"])\n","#     paragraph = df[column][\"text\"]\n","#     print(\"PARAGRAPH:\\n\", paragraph)\n","#     print(\"NOUN PHRASES:\\n\", getNounPhrases(paragraph))\n","#     print(\"EXPECTED:\\n\", wantedOutput)\n","#     print(\"*\" * 280)\n","#     print(\"\")"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"WreKyj_aG2PL","executionInfo":{"status":"ok","timestamp":1643348110054,"user_tz":480,"elapsed":3,"user":{"displayName":"Michael Robert Doboli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13681449374036728389"}}},"outputs":[],"source":["def findNounsWithLocs(text):\n","  '''This function takes in a block of text, finds the nouns in it and then returns an array of 1s and 0s representing where those nouns are'''\n","  originalText = text\n","  #modify text here however we please in getNounPhrases\n","  nounList = getNounPhrases(text)\n","  start = 0\n","  predicted_array = np.zeros(len(originalText))\n","\n","  for word in nounList:\n","    nounStartLoc = originalText.find(word, start)\n","    nounEndLoc = nounStartLoc + len(word)\n","\n","    if abs(originalText.find('$', start) - nounStartLoc) < 25:\n","      predicted_array[nounStartLoc : nounEndLoc] = 1\n","\n","    start = nounEndLoc\n","\n","  return predicted_array"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"ylM5UWpPIaHw","executionInfo":{"status":"ok","timestamp":1643348110602,"user_tz":480,"elapsed":550,"user":{"displayName":"Michael Robert Doboli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13681449374036728389"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f883d876-d985-40f6-9d6c-eb186a2bb848"},"outputs":[{"output_type":"stream","name":"stdout","text":["[0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"]}],"source":["print(findNounsWithLocs(\"The bus is yellow.\"))"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"luShAjMVOD-H","executionInfo":{"status":"ok","timestamp":1643348110603,"user_tz":480,"elapsed":7,"user":{"displayName":"Michael Robert Doboli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13681449374036728389"}}},"outputs":[],"source":["# for column in data:\n","#   paragraph = df[column][\"text\"]\n","#   print(\"PARAGRAPH:\\n\", paragraph)\n","#   print(\"NOUN PHRASES:\\n\", getNounPhrases(paragraph))\n","#   print(\"NOUN LOCATIONS:\\n\", findNounsWithLocs(paragraph))\n","#   print('*' * 280 + '\\n')"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"hXlFMmaEC4ix","executionInfo":{"status":"ok","timestamp":1643348110604,"user_tz":480,"elapsed":7,"user":{"displayName":"Michael Robert Doboli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13681449374036728389"}}},"outputs":[],"source":["def create_arrays(expected, predicted, len_text):\n","  expected_array = np.zeros(len_text)  \n","  predicted_array = np.zeros(len_text)\n","  for key in expected.keys():\n","    start_index = expected[key][\"start\"]\n","    end_index = expected[key][\"end\"]\n","    expected_array[start_index : end_index + 1] = 1\n","\n","  \n","  # for key in predicted.keys():\n","  #   start_index = predicted[key][\"start\"]\n","  #   end_index = predicted[key][\"end\"]\n","  #   predicted_array[start_index : end_index + 1] = 1\n","\n","  return (expected_array, predicted_array)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"UIlWJDCB-_AK","executionInfo":{"status":"ok","timestamp":1643348110604,"user_tz":480,"elapsed":7,"user":{"displayName":"Michael Robert Doboli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13681449374036728389"}}},"outputs":[],"source":["def compare(expected, predicted): #Computes the F1 score between expected and predicted\n","  expected_array = np.array(len())"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"Fuy6yJ6569ZV","executionInfo":{"status":"ok","timestamp":1643348110605,"user_tz":480,"elapsed":7,"user":{"displayName":"Michael Robert Doboli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13681449374036728389"}}},"outputs":[],"source":["def framework(df):\n","  results = []\n","  recalls = []\n","  for column in df:\n","    paragraph = df[column][\"text\"]\n","    expected = df[column][\"entity\"]\n","    primary_description = extract_primary_description(expected)\n","    predicted = paragraph\n","    if len(primary_description) != 0:\n","      recalls.append(calculate_recall(getNounPhrases(predicted), primary_description))\n","    # expected_array, predicted_array = create_arrays(primary_description, predicted, len(paragraph))\n","    expected_array, predicted_array = create_arrays(primary_description, predicted, len(paragraph))\n","    predicted_array = findNounsWithLocs(paragraph)\n","    result = f1_score(expected_array, predicted_array, average= \"binary\", zero_division = 1)\n","    results.append(result)\n","  print(\"Average F1 score is:\", sum(results) / len(results))\n","  print(\"Average recall: \", sum(recalls) / len(recalls))\n"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"GdqC_gx7Vn0F","executionInfo":{"status":"ok","timestamp":1643348110607,"user_tz":480,"elapsed":9,"user":{"displayName":"Michael Robert Doboli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13681449374036728389"}}},"outputs":[],"source":["def framework_recall(df):\n","  results = []\n","  recalls = []\n","  for column in df:\n","    paragraph = df[column][\"text\"]\n","    expected = df[column][\"entity\"]\n","    primary_description = extract_primary_description(expected)\n","    res = {}\n","    if len(primary_description) != 0:\n","      cnt = 0\n","      sentences = nltk.tokenize.sent_tokenize(paragraph)\n","      for sent in sentences:\n","        # print(sent)\n","        # print(getNounPhrases(sent, cnt))\n","        recalls.append(calculate_recall(getNounPhrases(sent), primary_description))\n","        cnt += len(sent)\n","  print(recalls)\n","  print(\"Average recall: \", sum(recalls) / len(recalls))\n"]},{"cell_type":"code","source":["# framework_recall(pd.read_json(filename))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"id":"JMF06dz8-HkA","executionInfo":{"status":"error","timestamp":1643348111271,"user_tz":480,"elapsed":673,"user":{"displayName":"Michael Robert Doboli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13681449374036728389"}},"outputId":"86e4849f-bda6-4736-eef2-b0f3e12b68d5"},"execution_count":20,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-bf21133f7807>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mframework_recall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'filename' is not defined"]}]},{"cell_type":"code","source":["df = pd.read_json(\"physics.atom_ph-ann10.json\")\n","expected = df[column][\"entity\"]\n","primary_description = extract_primary_description(expected)\n","paragraph = data.loc[\"text\"][0]\n","cnt = 0\n","sentences = nltk.tokenize.sent_tokenize(paragraph)\n","result = {}\n","for sent in sentences:\n","  res = getNounPhrases(sent)\n","  calculate_recall(res, )\n","  cnt += len(sent)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":400},"id":"63bjIvZkDYFd","executionInfo":{"status":"error","timestamp":1643348219445,"user_tz":480,"elapsed":154,"user":{"displayName":"Michael Robert Doboli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13681449374036728389"}},"outputId":"315dfd04-a5da-4659-b717-51b3b984511f"},"execution_count":28,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-856d5867561f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"physics.atom_ph-ann10.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"entity\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprimary_description\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_primary_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mparagraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 )\n\u001b[1;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression, nrows)\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_close\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    753\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"series\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m-> 1119\u001b[0;31m                 \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m             )\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Expected object or value"]}]},{"cell_type":"code","execution_count":22,"metadata":{"id":"7JJo6VII_N-d","executionInfo":{"status":"ok","timestamp":1643348121332,"user_tz":480,"elapsed":10,"user":{"displayName":"Michael Robert Doboli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13681449374036728389"}}},"outputs":[],"source":["#\"The current F1 score of 0.355 arises when we leave the predicted_array all full of zeroes and compare with the expected.\"\n","# 0.261 is our current best implementing NLP techniques w/ <25\n","# framework(data)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"fXXqZCuvWKKr","executionInfo":{"status":"error","timestamp":1643348123067,"user_tz":480,"elapsed":750,"user":{"displayName":"Michael Robert Doboli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13681449374036728389"}},"colab":{"base_uri":"https://localhost:8080/","height":400},"outputId":"bb9aa04b-d1a9-418c-b35d-b8a20b9108d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["physics.atom_ph-ann10.json\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-d76b92aba466>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataFiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/primary_description/Practice/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mframework_recall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-ac23dc475955>\u001b[0m in \u001b[0;36mframework_recall\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# print(sent)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# print(getNounPhrases(sent, cnt))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mrecalls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_recall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetNounPhrases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimary_description\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mcnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecalls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-d777d0caa330>\u001b[0m in \u001b[0;36mcalculate_recall\u001b[0;34m(noun_dict, expected)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_recall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoun_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mnoun_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnoun_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m       \u001b[0mnoun_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'keys'"]}],"source":["dataFiles = []\n","pwd = '/content/drive/My Drive/primary_description/Practice'\n","for filename in os.listdir(pwd):\n","    if filename.endswith(\"json\"): \n","        dataFiles.append(pwd + '/' + filename)\n","for filename in dataFiles:\n","  print(filename.replace('/content/drive/My Drive/primary_description/Practice/', \"\"))\n","  framework_recall(pd.read_json(filename))\n","  print()"]},{"cell_type":"markdown","metadata":{"id":"Wvy8cN93PNpg"},"source":[""]},{"cell_type":"code","execution_count":24,"metadata":{"id":"PktY8mjkTvfD","executionInfo":{"status":"ok","timestamp":1643348123914,"user_tz":480,"elapsed":3,"user":{"displayName":"Michael Robert Doboli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13681449374036728389"}}},"outputs":[],"source":["# dataFiles = []\n","# pwd = '/content/drive/My Drive/primary_description/Practice'\n","# for filename in os.listdir(pwd):\n","#     if filename.endswith(\"json\"): \n","#         dataFiles.append(pwd + '/' + filename)\n","# for filename in dataFiles:\n","#   print(filename.replace('/content/drive/My Drive/primary_description/Practice/', \"\"))\n","#   framework(pd.read_json(filename))\n","#   print()"]},{"cell_type":"code","source":["def get_descriptions_paragraph(paragraph):\n","    sentences = nltk.tokenize.sent_tokenize(paragraph)\n","    answer = {}\n","    cnt = 0\n","    for sent in sentences:\n","      features = getNounPhrases(sent)\n","      for feature in features:  ##TODO: Consider case where a word occurs multiple times in a sentence##\n","        if sent.find(feature) > -1:\n","          start = cnt + sent.find(feature)\n","          end = start + len(feature)\n","          answer[feature] = (start, end)\n","      cnt += len(sent)\n","    return {k: v for k, v in sorted(answer.items(), key=lambda item: item[1])}\n"],"metadata":{"id":"LshDEbo8J7lQ","executionInfo":{"status":"ok","timestamp":1643349052905,"user_tz":480,"elapsed":191,"user":{"displayName":"Michael Robert Doboli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13681449374036728389"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["def descriptor_to_output(descriptors):\n","    entity = {}\n","    num = 1\n","    for desc in descriptors.keys():\n","      eid = 'T' + str(num)\n","      num += 1\n","      entity[eid] = {}\n","      entity[eid]['eid'] = eid\n","      entity[eid]['label'] = 'PRIMARY'\n","      entity[eid]['start'] = descriptors[desc][0]\n","      entity[eid]['end'] = descriptors[desc][1]\n","      entity[eid]['text'] = desc\n","\n","    return entity"],"metadata":{"id":"OR2v2XsJPgRs","executionInfo":{"status":"ok","timestamp":1643349418882,"user_tz":480,"elapsed":164,"user":{"displayName":"Michael Robert Doboli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13681449374036728389"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["df = pd.read_json(\"Practice/physics.atom_ph-ann10.json\")\n","paragraph = df.loc[\"text\"][10]\n","descriptors = get_descriptions_paragraph(paragraph)\n","output = descriptor_to_output(descriptors)\n","print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8VmK-F1sLmNX","executionInfo":{"status":"ok","timestamp":1643349484301,"user_tz":480,"elapsed":424,"user":{"displayName":"Michael Robert Doboli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13681449374036728389"}},"outputId":"77b2b1df-e461-4c90-c907-ef5a13305629"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["{'T1': {'eid': 'T1', 'label': 'PRIMARY', 'start': 6, 'end': 14, 'text': 'evaluate'}, 'T2': {'eid': 'T2', 'label': 'PRIMARY', 'start': 45, 'end': 58, 'text': 'count streams'}, 'T3': {'eid': 'T3', 'label': 'PRIMARY', 'start': 62, 'end': 66, 'text': 'tens'}, 'T4': {'eid': 'T4', 'label': 'PRIMARY', 'start': 62, 'end': 82, 'text': 'tens of milliseconds'}, 'T5': {'eid': 'T5', 'label': 'PRIMARY', 'start': 70, 'end': 82, 'text': 'milliseconds'}, 'T6': {'eid': 'T6', 'label': 'PRIMARY', 'start': 88, 'end': 92, 'text': 'find'}, 'T7': {'eid': 'T7', 'label': 'PRIMARY', 'start': 117, 'end': 126, 'text': 'dominated'}, 'T8': {'eid': 'T8', 'label': 'PRIMARY', 'start': 130, 'end': 165, 'text': 'the bistable switching shown in Fig'}, 'T9': {'eid': 'T9', 'label': 'PRIMARY', 'start': 134, 'end': 158, 'text': 'bistable switching shown'}, 'T10': {'eid': 'T10', 'label': 'PRIMARY', 'start': 172, 'end': 251, 'text': 'a ) of the text and relatively slow fluctuations in the ring laser output power'}, 'T11': {'eid': 'T11', 'label': 'PRIMARY', 'start': 224, 'end': 251, 'text': 'the ring laser output power'}, 'T12': {'eid': 'T12', 'label': 'PRIMARY', 'start': 228, 'end': 251, 'text': 'ring laser output power'}, 'T13': {'eid': 'T13', 'label': 'PRIMARY', 'start': 257, 'end': 261, 'text': 'data'}, 'T14': {'eid': 'T14', 'label': 'PRIMARY', 'start': 283, 'end': 302, 'text': 'therefore corrected'}, 'T15': {'eid': 'T15', 'label': 'PRIMARY', 'start': 306, 'end': 313, 'text': 'follows'}, 'T16': {'eid': 'T16', 'label': 'PRIMARY', 'start': 320, 'end': 331, 'text': 'short times'}, 'T17': {'eid': 'T17', 'label': 'PRIMARY', 'start': 332, 'end': 392, 'text': 'the laser emission is assumed to be in a pure coherent state'}, 'T18': {'eid': 'T18', 'label': 'PRIMARY', 'start': 336, 'end': 350, 'text': 'laser emission'}, 'T19': {'eid': 'T19', 'label': 'PRIMARY', 'start': 371, 'end': 392, 'text': 'a pure coherent state'}, 'T20': {'eid': 'T20', 'label': 'PRIMARY', 'start': 373, 'end': 392, 'text': 'pure coherent state'}, 'T21': {'eid': 'T21', 'label': 'PRIMARY', 'start': 406, 'end': 427, 'text': 'directional switching'}, 'T22': {'eid': 'T22', 'label': 'PRIMARY', 'start': 443, 'end': 460, 'text': 'slow fluctuations'}, 'T23': {'eid': 'T23', 'label': 'PRIMARY', 'start': 464, 'end': 484, 'text': 'average output power'}, 'T24': {'eid': 'T24', 'label': 'PRIMARY', 'start': 486, 'end': 487, 'text': 'T'}, 'T25': {'eid': 'T25', 'label': 'PRIMARY', 'start': 491, 'end': 498, 'text': 'results'}, 'T26': {'eid': 'T26', 'label': 'PRIMARY', 'start': 502, 'end': 562, 'text': 'a conditional probability distribution for the photon number'}, 'T27': {'eid': 'T27', 'label': 'PRIMARY', 'start': 504, 'end': 540, 'text': 'conditional probability distribution'}, 'T28': {'eid': 'T28', 'label': 'PRIMARY', 'start': 545, 'end': 562, 'text': 'the photon number'}, 'T29': {'eid': 'T29', 'label': 'PRIMARY', 'start': 549, 'end': 562, 'text': 'photon number'}, 'T30': {'eid': 'T30', 'label': 'PRIMARY', 'start': 563, 'end': 564, 'text': '$'}, 'T31': {'eid': 'T31', 'label': 'PRIMARY', 'start': 567, 'end': 572, 'text': 'given'}, 'T32': {'eid': 'T32', 'label': 'PRIMARY', 'start': 581, 'end': 583, 'text': 'RT'}, 'T33': {'eid': 'T33', 'label': 'PRIMARY', 'start': 596, 'end': 599, 'text': '-RT'}, 'T34': {'eid': 'T34', 'label': 'PRIMARY', 'start': 600, 'end': 602, 'text': '/n'}, 'T35': {'eid': 'T35', 'label': 'PRIMARY', 'start': 620, 'end': 625, 'text': 'the r'}, 'T36': {'eid': 'T36', 'label': 'PRIMARY', 'start': 624, 'end': 640, 'text': 'randomly varying'}, 'T37': {'eid': 'T37', 'label': 'PRIMARY', 'start': 641, 'end': 665, 'text': 'instantaneous count rate'}, 'T38': {'eid': 'T38', 'label': 'PRIMARY', 'start': 677, 'end': 723, 'text': 'a time which is much greater than the range of'}, 'T39': {'eid': 'T39', 'label': 'PRIMARY', 'start': 677, 'end': 725, 'text': 'a time which is much greater than the range of $'}, 'T40': {'eid': 'T40', 'label': 'PRIMARY', 'start': 679, 'end': 683, 'text': 'time'}, 'T41': {'eid': 'T41', 'label': 'PRIMARY', 'start': 711, 'end': 723, 'text': 'the range of'}, 'T42': {'eid': 'T42', 'label': 'PRIMARY', 'start': 715, 'end': 720, 'text': 'range'}, 'T43': {'eid': 'T43', 'label': 'PRIMARY', 'start': 731, 'end': 741, 'text': 'considered'}, 'T44': {'eid': 'T44', 'label': 'PRIMARY', 'start': 761, 'end': 792, 'text': 'the time scale of the switching'}, 'T45': {'eid': 'T45', 'label': 'PRIMARY', 'start': 765, 'end': 775, 'text': 'time scale'}, 'T46': {'eid': 'T46', 'label': 'PRIMARY', 'start': 779, 'end': 792, 'text': 'the switching'}, 'T47': {'eid': 'T47', 'label': 'PRIMARY', 'start': 783, 'end': 792, 'text': 'switching'}, 'T48': {'eid': 'T48', 'label': 'PRIMARY', 'start': 805, 'end': 829, 'text': 'conditional distribution'}, 'T49': {'eid': 'T49', 'label': 'PRIMARY', 'start': 832, 'end': 864, 'text': 'the probability distribution for'}, 'T50': {'eid': 'T50', 'label': 'PRIMARY', 'start': 836, 'end': 837, 'text': 'p'}, 'T51': {'eid': 'T51', 'label': 'PRIMARY', 'start': 836, 'end': 860, 'text': 'probability distribution'}, 'T52': {'eid': 'T52', 'label': 'PRIMARY', 'start': 872, 'end': 878, 'text': '$p(n)='}, 'T53': {'eid': 'T53', 'label': 'PRIMARY', 'start': 914, 'end': 941, 'text': 'the probability density for'}, 'T54': {'eid': 'T54', 'label': 'PRIMARY', 'start': 918, 'end': 937, 'text': 'probability density'}, 'T55': {'eid': 'T55', 'label': 'PRIMARY', 'start': 963, 'end': 968, 'text': 'finds'}, 'T56': {'eid': 'T56', 'label': 'PRIMARY', 'start': 1097, 'end': 1106, 'text': 'eqnarray*'}, 'T57': {'eid': 'T57', 'label': 'PRIMARY', 'start': 1108, 'end': 1113, 'text': 'Using'}, 'T58': {'eid': 'T58', 'label': 'PRIMARY', 'start': 1112, 'end': 1113, 'text': 'g'}, 'T59': {'eid': 'T59', 'label': 'PRIMARY', 'start': 1114, 'end': 1127, 'text': 'the fact that'}, 'T60': {'eid': 'T60', 'label': 'PRIMARY', 'start': 1118, 'end': 1122, 'text': 'fact'}, 'T61': {'eid': 'T61', 'label': 'PRIMARY', 'start': 1168, 'end': 1169, 'text': '='}, 'T62': {'eid': 'T62', 'label': 'PRIMARY', 'start': 1220, 'end': 1223, 'text': 'var'}, 'T63': {'eid': 'T63', 'label': 'PRIMARY', 'start': 1294, 'end': 1302, 'text': 'choosing'}, 'T64': {'eid': 'T64', 'label': 'PRIMARY', 'start': 1331, 'end': 1332, 'text': 'R'}, 'T65': {'eid': 'T65', 'label': 'PRIMARY', 'start': 1353, 'end': 1372, 'text': 'a correction factor'}, 'T66': {'eid': 'T66', 'label': 'PRIMARY', 'start': 1355, 'end': 1372, 'text': 'correction factor'}, 'T67': {'eid': 'T67', 'label': 'PRIMARY', 'start': 1421, 'end': 1427, 'text': 'series'}, 'T68': {'eid': 'T68', 'label': 'PRIMARY', 'start': 1431, 'end': 1442, 'text': 'time stamps'}, 'T69': {'eid': 'T69', 'label': 'PRIMARY', 'start': 1431, 'end': 1497, 'text': 'time stamps were recorded under similar conditions above threshold'}, 'T70': {'eid': 'T70', 'label': 'PRIMARY', 'start': 1463, 'end': 1481, 'text': 'similar conditions'}, 'T71': {'eid': 'T71', 'label': 'PRIMARY', 'start': 1488, 'end': 1497, 'text': 'threshold'}, 'T72': {'eid': 'T72', 'label': 'PRIMARY', 'start': 1545, 'end': 1560, 'text': 'the set at each'}, 'T73': {'eid': 'T73', 'label': 'PRIMARY', 'start': 1549, 'end': 1552, 'text': 'set'}, 'T74': {'eid': 'T74', 'label': 'PRIMARY', 'start': 1571, 'end': 1577, 'text': 'obtain'}, 'T75': {'eid': 'T75', 'label': 'PRIMARY', 'start': 1578, 'end': 1595, 'text': 'the points in Fig'}, 'T76': {'eid': 'T76', 'label': 'PRIMARY', 'start': 1582, 'end': 1588, 'text': 'points'}, 'T77': {'eid': 'T77', 'label': 'PRIMARY', 'start': 1592, 'end': 1595, 'text': 'Fig'}, 'T78': {'eid': 'T78', 'label': 'PRIMARY', 'start': 1602, 'end': 1603, 'text': 'b'}, 'T79': {'eid': 'T79', 'label': 'PRIMARY', 'start': 1609, 'end': 1617, 'text': 'the text'}, 'T80': {'eid': 'T80', 'label': 'PRIMARY', 'start': 1613, 'end': 1617, 'text': 'text'}, 'T81': {'eid': 'T81', 'label': 'PRIMARY', 'start': 1619, 'end': 1619, 'text': ''}, 'T82': {'eid': 'T82', 'label': 'PRIMARY', 'start': 1622, 'end': 1628, 'text': 'stress'}, 'T83': {'eid': 'T83', 'label': 'PRIMARY', 'start': 1639, 'end': 1649, 'text': 'correction'}, 'T84': {'eid': 'T84', 'label': 'PRIMARY', 'start': 1650, 'end': 1663, 'text': 'only rescales'}, 'T85': {'eid': 'T85', 'label': 'PRIMARY', 'start': 1664, 'end': 1680, 'text': 'the magnitude of'}, 'T86': {'eid': 'T86', 'label': 'PRIMARY', 'start': 1668, 'end': 1677, 'text': 'magnitude'}, 'T87': {'eid': 'T87', 'label': 'PRIMARY', 'start': 1681, 'end': 1690, 'text': '$g^{(2)}('}, 'T88': {'eid': 'T88', 'label': 'PRIMARY', 'start': 1699, 'end': 1724, 'text': 'the lack of dependence on'}, 'T89': {'eid': 'T89', 'label': 'PRIMARY', 'start': 1703, 'end': 1707, 'text': 'lack'}, 'T90': {'eid': 'T90', 'label': 'PRIMARY', 'start': 1711, 'end': 1721, 'text': 'dependence'}, 'T91': {'eid': 'T91', 'label': 'PRIMARY', 'start': 1711, 'end': 1724, 'text': 'dependence on'}, 'T92': {'eid': 'T92', 'label': 'PRIMARY', 'start': 1735, 'end': 1774, 'text': 'already a feature of the raw histograms'}, 'T93': {'eid': 'T93', 'label': 'PRIMARY', 'start': 1743, 'end': 1774, 'text': 'a feature of the raw histograms'}, 'T94': {'eid': 'T94', 'label': 'PRIMARY', 'start': 1745, 'end': 1752, 'text': 'feature'}, 'T95': {'eid': 'T95', 'label': 'PRIMARY', 'start': 1756, 'end': 1774, 'text': 'the raw histograms'}, 'T96': {'eid': 'T96', 'label': 'PRIMARY', 'start': 1760, 'end': 1774, 'text': 'raw histograms'}}\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"53c4cHlPNO1B"},"execution_count":null,"outputs":[]}]}